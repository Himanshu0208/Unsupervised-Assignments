{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d553885",
   "metadata": {},
   "source": [
    "# __Ques 1__\n",
    "A confusion matrix is also known as contigency matrix. its a table that shows the performance of a classification problem by showing the true-positive, true-negative, false-positive, false-negtive"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85da326e",
   "metadata": {},
   "source": [
    "# __Ques 2__\n",
    "A pair confusion matrix, also known as a pairwise confusion matrix, is an extension of a regular confusion matrix that focuses on the pairwise comparison of classes in multi-class classification problems. It provides a more detailed analysis of the model's performance by capturing the confusion between each pair of classes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73502194",
   "metadata": {},
   "source": [
    "# __Ques 3__\n",
    " Extrinsic evaluation measures the performance of a language model by assessing its performance on a specific downstream task or application. It focuses on evaluating how well the language model performs in a real-world application for which it was designed. The evaluation is done by integrating the language model into a larger system and measuring its impact on the overall performance of that system."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b488738",
   "metadata": {},
   "source": [
    "# __Ques 4__\n",
    "Intrinsic evaluation measures the performance of a language model by assessing its performance on specific language-related tasks or evaluations that are typically isolated from the context of a larger application. It focuses on evaluating the language model's performance in terms of its linguistic capabilities, such as grammar, fluency, coherence, and lexical semantics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c599593c",
   "metadata": {},
   "source": [
    "# __Ques 5__\n",
    "- Performance evaluation: The confusion matrix allows you to calculate various evaluation metrics that provide insights into the model's performance, such as accuracy, precision, recall, specificity, and F1 score. These metrics help you understand how well the model is performing overall and for each class.\n",
    "\n",
    "- Error analysis: By analyzing the confusion matrix, you can identify the types of errors the model is making. For example, false positives and false negatives can indicate specific areas where the model is struggling. This analysis helps you gain insights into the particular weaknesses or challenges faced by the model.\n",
    "\n",
    "- Class-specific analysis: The confusion matrix provides class-specific performance metrics, allowing you to evaluate the model's performance for each individual class. This helps you understand if the model is performing well for all classes or if there are certain classes for which it is struggling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1e3e9c4",
   "metadata": {},
   "source": [
    "# __Ques 6__\n",
    "- __Silhouette Coefficient:__ The Silhouette Coefficient quantifies the quality of clustering by measuring the compactness and separation of clusters. It ranges from -1 to 1, where a higher value indicates better clustering. A coefficient close to 1 suggests well-separated and compact clusters, while a value close to -1 indicates overlapping or poorly separated clusters.\n",
    "\n",
    "- __Davies-Bouldin Index:__ The Davies-Bouldin Index evaluates the quality of clustering by measuring both the compactness and separation of clusters. It computes the average similarity between each cluster and its most similar neighboring cluster. A lower index value indicates better clustering, with 0 indicating perfect clustering\n",
    "\n",
    "- __Explained Variance Ratio__ In the context of dimensionality reduction techniques like Principal Component Analysis (PCA), the explained variance ratio measures the amount of variance in the data explained by each principal component. It helps assess the amount of information retained by the reduced-dimensional representation. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63455a1e",
   "metadata": {},
   "source": [
    "# __Ques 7__\n",
    "Using accuracy as a sole evaluation metric for classification tasks has several limitations\n",
    "1. Imbalanced Datasets\n",
    "2. class distribution shift\n",
    "3. cost sensitive classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee497e86",
   "metadata": {},
   "source": [
    "To address these limitations, alternative evaluation metrics and techniques can be\n",
    "1. confusion matrix\n",
    "2. cross-validation\n",
    "3. ensemble techniques"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
