{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d657b265",
   "metadata": {},
   "source": [
    "# __Ques 1__\n",
    "Anomaly detection is the process of finding the noise/outliers in the datapoints. Many time's its very usefull for the Machine Learning Engg. to deal with noise/outliers as some time's there are a lot valuable. like a person logging to my google account from a new device it can be hacker so the google will detect him and ask me about authorization "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e0df227",
   "metadata": {},
   "source": [
    "# __Ques 2__\n",
    "the challenges in anomaly detection are:-\n",
    "- Imbalanced dataset\n",
    "- Lack of clear sepration\n",
    "- Intrepebility"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afce9346",
   "metadata": {},
   "source": [
    "# __Ques 3__\n",
    "Unsupervised Anomaly Detection:\n",
    "\n",
    "- Labeled Data: Unsupervised anomaly detection works without any labeled anomalies during training. It relies solely on the characteristics of the majority class (normal instances) to identify anomalies. The algorithm learns the normal patterns or structures from the unlabeled data and detects instances that significantly deviate from the learned normal behavior.\n",
    "\n",
    "- Training Phase: In the unsupervised approach, the algorithm explores the data distribution to identify regions of high density (normal instances) and considers instances lying in sparser regions as anomalies. It does not require prior knowledge or specific labels for anomalies.\n",
    "\n",
    "- Anomaly Detection: Unsupervised anomaly detection algorithms determine anomalies based on their deviation from the normal data distribution or the density of instances. Common methods include statistical approaches like Gaussian distribution modeling, clustering-based methods like DBSCAN or isolation forest, and distance-based methods like k-nearest neighbors.\n",
    "\n",
    "- Applicability: Unsupervised anomaly detection is useful when labeled anomalies are scarce, difficult to obtain, or when anomalies have unknown characteristics or patterns. It is applicable in situations where the focus is on detecting unknown or novel anomalies that may not be present in the training data.\n",
    "\n",
    "Supervised Anomaly Detection:\n",
    "\n",
    "- Labeled Data: Supervised anomaly detection requires a labeled dataset during the training phase. The dataset includes both normal instances and labeled anomalies. The algorithm learns from the labeled anomalies to identify their specific patterns or characteristics.\n",
    "\n",
    "- Training Phase: In the supervised approach, the algorithm is trained using a combination of normal instances and labeled anomalies. The goal is to learn a model that can distinguish between normal and anomalous instances based on the provided labels.\n",
    "\n",
    "- Anomaly Detection: During the testing phase, the supervised anomaly detection algorithm applies the learned model to new, unlabeled instances and predicts whether they are normal or anomalous based on the patterns it learned from the labeled anomalies.\n",
    "\n",
    "- Applicability: Supervised anomaly detection is suitable when a sufficient amount of labeled anomalies is available for training. It is particularly effective in scenarios where the characteristics or patterns of anomalies are known, and the goal is to identify instances that exhibit similar patterns to the labeled anomalies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eec8a86",
   "metadata": {},
   "source": [
    "# __Ques 4__\n",
    "- statical\n",
    "- information theory\n",
    "- machine learning\n",
    "- domain specific"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63b1b4bf",
   "metadata": {},
   "source": [
    "# __Ques 5__\n",
    "- distance measure\n",
    "- distance threshold\n",
    "- nearest neghibours value\n",
    "- data independence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b826c93",
   "metadata": {},
   "source": [
    "# __Ques 6__\n",
    "the lof algo first check the nearest k neghibours than check nearest k neghibourse of each negihbour and calulate the local density of both of them and if the local density of neghibours is more than that of the current point than its treated as local outlier and is the local density of point is more than its neghibours local density than its treated as a normal point"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26a89ecd",
   "metadata": {},
   "source": [
    "# __Ques 7__\n",
    "- contamination => it tell about the threshold value of anomally acore to determine the outlier\n",
    "- n_estimators => the number of tree to be formed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "146b554c",
   "metadata": {},
   "source": [
    "# __Ques 8__\n",
    "Since the data point does not have the required number of neighbors (K=10), it may not be possible to accurately calculate the anomaly score using KNN with K=10 in this case. The anomaly score in KNN is typically based on the distances or dissimilarities to the K nearest neighbors, and having a sufficient number of neighbors is essential for reliable anomaly scoring."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c17198b4",
   "metadata": {},
   "source": [
    "# __Ques 9__\n",
    "assume the average path length to be 4.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "97f0aab7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anomaly Score is =>  0.3714985722842371\n"
     ]
    }
   ],
   "source": [
    "n = 3000\n",
    "tree = 100\n",
    "apl = 5.0 # given\n",
    "aplt = 4.5\n",
    "\n",
    "score = 2 ** -(5/3.5)\n",
    "print(\"Anomaly Score is => \",score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
